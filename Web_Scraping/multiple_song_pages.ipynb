{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "atlantic-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.uk-charts.top-source.info/top-100-2000.shtml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "numerical-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "consistent-feeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accomplished-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-strengthening",
   "metadata": {},
   "source": [
    "#### how to scrape multiple pages ? \n",
    "\n",
    "looking at the selected urls we have a new page for each year \n",
    "2000,2001,2002,2003...2009\n",
    "\n",
    "so, we will define a start variable that goes into the url \n",
    "(having looked at what the next page url looks like)\n",
    "\n",
    "example from last time : \n",
    "    \n",
    "- iterations = range(1,502,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "otherwise-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = range(2000,2010,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "crude-survival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n"
     ]
    }
   ],
   "source": [
    "#check the iteration / range works \n",
    "for i in iterations:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "arabic-iceland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.uk-charts.top-source.info/top-100-2009.shtml'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the full url string based on the page search \n",
    "#(and test the urls with the iteration)\n",
    "f_url=f\"https://www.uk-charts.top-source.info/top-100-{i}.shtml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "liable-example",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in iterations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "serial-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_lst=[f\"https://www.uk-charts.top-source.info/top-100-{i}.shtml\" for i in iterations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "strange-bachelor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.uk-charts.top-source.info/top-100-2000.shtml',\n",
       " 'https://www.uk-charts.top-source.info/top-100-2001.shtml',\n",
       " 'https://www.uk-charts.top-source.info/top-100-2002.shtml',\n",
       " 'https://www.uk-charts.top-source.info/top-100-2003.shtml',\n",
       " 'https://www.uk-charts.top-source.info/top-100-2004.shtml',\n",
       " 'https://www.uk-charts.top-source.info/top-100-2005.shtml',\n",
       " 'https://www.uk-charts.top-source.info/top-100-2006.shtml',\n",
       " 'https://www.uk-charts.top-source.info/top-100-2007.shtml',\n",
       " 'https://www.uk-charts.top-source.info/top-100-2008.shtml',\n",
       " 'https://www.uk-charts.top-source.info/top-100-2009.shtml']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test these to confirm our url method\n",
    "url_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-coordinator",
   "metadata": {},
   "source": [
    "### respectful scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "confirmed-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adjustable-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple example \n",
    "#for i in range(5):\n",
    "    #print(i)\n",
    "    #sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "lonely-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enhance with random integers \n",
    "from random import randint\n",
    "#for i in range(5):\n",
    "    #print(i)\n",
    "    #wait_time=randint(1,4)\n",
    "    #print(\"i will sleep for \"+ str(wait_time) +\"seconds\")\n",
    "    #sleep(wait_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-dialogue",
   "metadata": {},
   "source": [
    "### putting everything together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "finite-hands",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "Status code: 200\n",
      "Status code: 200\n",
      "Status code: 200\n",
      "Status code: 200\n",
      "Status code: 200\n",
      "Status code: 200\n",
      "Status code: 200\n",
      "Status code: 200\n",
      "Status code: 200\n"
     ]
    }
   ],
   "source": [
    "#we are building everything from scratch here \n",
    "\n",
    "pages= []\n",
    "\n",
    "for i in iterations: \n",
    "    #takes the iteration, turns it into a string (not needed)\n",
    "    start_at = str(i)\n",
    "    #define the url\n",
    "    url= f\"https://www.uk-charts.top-source.info/top-100-{start_at}.shtml\"\n",
    "    # download the url content \n",
    "    response = requests.get(url)\n",
    "    #print status code \n",
    "    print(\"Status code: \"+ str(response.status_code))\n",
    "    #to capture the data and fill in the list\n",
    "    pages.append(response)\n",
    "    #add a respectful nap \n",
    "    wait_time=randint(1,3)\n",
    "    sleep(wait_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "furnished-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(pages[0].content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-solomon",
   "metadata": {},
   "source": [
    "### next steps - tidying up \n",
    "next thing to think about is can we reduce how much useless html we have scraped - maybe its not necessary to store it all in the list ? \n",
    "\n",
    "what we want eventually is song name, artist, year, index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-european",
   "metadata": {},
   "source": [
    "- by inspecting the webpage- identify from the html how to get the information we want for the soup\n",
    "\n",
    "- paste selector from a chosen song\n",
    "\n",
    "#ContentColumn > div > table > tbody > tr:nth-child(1) > td:nth-child(3) \n",
    "\n",
    "- same process for artist\n",
    "\n",
    "#ContentColumn > div > table > tbody > tr:nth-child(1) > td:nth-child(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "personal-intro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td>Who Let The Dogs Out</td>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#you can try changing the nth child number to run down the list on the page\n",
    "soup.select(\"#ContentColumn > div > table > tbody > tr:nth-child(1) > td:nth-child(3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "generous-wayne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who Let The Dogs Out'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#you can trim the css selector to get the same results- only the text\n",
    "soup.select(\"td:nth-child(3)\")[0].text\n",
    "#changing the index goes to the next song "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this means we can select all songs by trimming the code \n",
    "soup.select(\"td:nth-child(3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same for the singers \n",
    "soup.select(\"td:nth-child(2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-latitude",
   "metadata": {},
   "source": [
    "### putting it all together \n",
    "this is what we need \n",
    "\n",
    "- soup.select(\"td:nth-child(3)\")\n",
    "- soup.select(\"td:nth-child(2)\")\n",
    "- soup=BeautifulSoup(pages[0].content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "typical-czech",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Response [200]>,\n",
       " <Response [200]>,\n",
       " <Response [200]>,\n",
       " <Response [200]>,\n",
       " <Response [200]>,\n",
       " <Response [200]>,\n",
       " <Response [200]>,\n",
       " <Response [200]>,\n",
       " <Response [200]>,\n",
       " <Response [200]>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plus ...\n",
    "pages\n",
    "# for every page make a soup\n",
    "# apply select functions\n",
    "# from results extract songs\n",
    "# append to the list song and singer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "other-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "song= []\n",
    "singer = []\n",
    "pages_parsed = []\n",
    "\n",
    "for i in range(len(pages)):\n",
    "    pages_parsed.append(BeautifulSoup(pages[i].content, \"html.parser\"))\n",
    "    songs_html = pages_parsed[i].select(\"td:nth-child(3)\")\n",
    "    singers_html = pages_parsed[i].select(\"td:nth-child(2)\")\n",
    "    \n",
    "    for j in range(len(songs_html)):\n",
    "        song.append(songs_html[j].get_text())\n",
    "        singer.append(singers_html[j].get_text())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "affected-national",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10, 1000)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing to check the numbers retrieved \n",
    "len(song), len(pages_parsed), len(singer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-collection",
   "metadata": {},
   "source": [
    "### Next step \n",
    "Now we have our for loop to collect the information, lets complete the task by converting our lists to a df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "central-thursday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>singer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who Let The Dogs Out</td>\n",
       "      <td>Baha Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It Feels So Good</td>\n",
       "      <td>Sonique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Real Slim Shady</td>\n",
       "      <td>Eminem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rise</td>\n",
       "      <td>Gabrielle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pure Shores</td>\n",
       "      <td>All Saints</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>19 / 2000</td>\n",
       "      <td>Gorillaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Ain't It Funny</td>\n",
       "      <td>Jennifer Lopez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Things I've Seen</td>\n",
       "      <td>Spooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Electric Avenue</td>\n",
       "      <td>Eddy Grant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Romeo</td>\n",
       "      <td>Basement Jaxx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     song          singer\n",
       "0    Who Let The Dogs Out        Baha Men\n",
       "1        It Feels So Good         Sonique\n",
       "2     The Real Slim Shady          Eminem\n",
       "3                    Rise       Gabrielle\n",
       "4             Pure Shores      All Saints\n",
       "..                    ...             ...\n",
       "195             19 / 2000        Gorillaz\n",
       "196        Ain't It Funny  Jennifer Lopez\n",
       "197      Things I've Seen          Spooks\n",
       "198       Electric Avenue      Eddy Grant\n",
       "199                 Romeo   Basement Jaxx\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making a pandas df from our data \n",
    "\n",
    "import pandas as pd \n",
    "songs =pd.DataFrame({'song':song, 'singer':singer})\n",
    "songs.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-southwest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-season",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-prophet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-novel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
